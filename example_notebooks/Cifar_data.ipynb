{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 10:43:29.667634: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-27 10:43:29.679942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761561809.711328 1129975 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761561809.721303 1129975 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761561809.742838 1129975 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761561809.742861 1129975 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761561809.742863 1129975 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761561809.742864 1129975 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-27 10:43:29.764823: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/zqianming/anaconda3/envs/MU_GPU/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 版本: 2.19.1\n",
      "GPU 设备列表: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "WARNING:tensorflow:From /tmp/ipykernel_1129975/3252794222.py:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU 是否可用: True\n",
      "内置 GPU 支持: True\n",
      "GPU 设备: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2907136707165293368\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23531028480\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12234558529558730558\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 8645246976\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17996612286196454990\n",
      "physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:07:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 2144165316\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761561813.138882 1129975 gpu_device.cc:2019] Created device /device:GPU:0 with 22440 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1761561813.161074 1129975 gpu_device.cc:2019] Created device /device:GPU:1 with 8244 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "I0000 00:00:1761561813.179172 1129975 gpu_device.cc:2019] Created device /device:GPU:0 with 22440 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1761561813.179350 1129975 gpu_device.cc:2019] Created device /device:GPU:1 with 8244 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow 版本:\", tf.__version__)\n",
    "print(\"GPU 设备列表:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU 是否可用:\", tf.test.is_gpu_available())\n",
    "print(\"内置 GPU 支持:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# 如果有 GPU，显示详细信息\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu = tf.config.list_physical_devices('GPU')[0]\n",
    "    print(\"GPU 设备:\", gpu)\n",
    "    \n",
    "    # 显示 GPU 内存信息\n",
    "    from tensorflow.python.client import device_lib\n",
    "    print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761561818.101012 1129975 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22440 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1761561818.101148 1129975 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 8244 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "data_dir = '../.data'\n",
    "cifar = tfds.load('cifar10', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 10:43:43.102449: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-10-27 10:43:48.829676: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-10-27 10:43:54.991079: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = list(zip(*((sample['image'], sample['label']) for sample in cifar['train'])))\n",
    "x_train = np.stack(x_train)\n",
    "y_train = np.stack(y_train)\n",
    "\n",
    "\n",
    "x_test, y_test = list(zip(*((sample['image'], sample['label']) for sample in cifar['test'])))\n",
    "x_test = np.stack(x_test)\n",
    "y_test = np.stack(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "n_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test = to_categorical(y_test, num_classes=n_classes)\n",
    "y_val = to_categorical(y_val, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conf import BASE_DIR\n",
    "\n",
    "data_dir = BASE_DIR/'train_test_data'/'Cifar-test'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for arr, filename in [\n",
    "        (x_train, 'x_train.npy'),\n",
    "        (y_train, 'y_train.npy'),\n",
    "        (x_test, 'x_test.npy'),\n",
    "        (y_test, 'y_test.npy'),\n",
    "        (x_val, 'x_valid.npy'),\n",
    "        (y_val, 'y_valid.npy')]:\n",
    "    np.save(data_dir/filename, arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MU_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
